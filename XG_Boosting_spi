import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from xgboost import XGBRegressor
import matplotlib.pyplot as plt
import os

# Veriyi yükleyelim
data = pd.read_csv('spi_data.csv')

# DateTime formatına çevirelim
data['date'] = pd.to_datetime(data['date'])
data.set_index('date', inplace=True)

# SPI değerlerini alalım
spi_values = data['spi'].values.reshape(-1, 1)

# Veriyi ölçeklendirelim
scaler = MinMaxScaler(feature_range=(0, 1))
spi_scaled = scaler.fit_transform(spi_values)

# Eğitim ve test verilerini hazırlayalım
train_size = int(len(spi_scaled) * 0.80)
train, test = spi_scaled[0:train_size], spi_scaled[train_size:len(spi_scaled)]

def create_dataset(dataset, look_back=1):
    X, Y = [], []
    for i in range(len(dataset) - look_back - 1):
        a = dataset[i:(i + look_back), 0]
        X.append(a)
        Y.append(dataset[i + look_back, 0])
    return np.array(X), np.array(Y)

look_back = 12  # 1 yıl
X_train, y_train = create_dataset(train, look_back)
X_test, y_test = create_dataset(test, look_back)

# XGBoost modeline uygun hale getirelim
# XGBoost için veriyi (örnekler, özellikler) oluşturuyoruz
X_train = X_train
X_test = X_test

# Modeli tanımlayalım
model = XGBRegressor(n_estimators=30, learning_rate=0.1, max_depth=100, objective='reg:squarederror')

# Modeli eğitelim
model.fit(X_train, y_train)

# Tahmin yapalım
train_predict = model.predict(X_train)
test_predict = model.predict(X_test)

# Tahminleri geri ölçeklendirelim
train_predict = scaler.inverse_transform(train_predict.reshape(-1, 1))
y_train = scaler.inverse_transform(y_train.reshape(-1, 1))
test_predict = scaler.inverse_transform(test_predict.reshape(-1, 1))
y_test = scaler.inverse_transform(y_test.reshape(-1, 1))

# Tahmin sonuçlarını zaman ekseniyle birlikte ekleyelim
train_predict_plot = np.empty_like(spi_values)
train_predict_plot[:, :] = np.nan
train_predict_plot[look_back:len(train_predict)+look_back, :] = train_predict

test_predict_plot = np.empty_like(spi_values)
test_predict_plot[:, :] = np.nan
test_predict_plot[len(train_predict)+(look_back*2)+1:len(spi_values)-1, :] = test_predict

# Tahmin sonuçlarını çizelim
plt.figure(figsize=(15, 6))
plt.plot(data.index, spi_values, label='Gerçek Değerler')
plt.plot(data.index, train_predict_plot, label='Eğitim Tahminleri')
plt.plot(data.index, test_predict_plot, label='Test Tahminleri')
plt.legend()
plt.savefig('tahmin_sonuclari_spi.png')
plt.show()

# Gelecek tahminleri için boş bir liste oluşturalım
future_predictions = []
last_data = spi_scaled[-look_back:].reshape(1, look_back)

for _ in range(50 * 12):  # 50 yıl, aylık tahminler
    future_pred = model.predict(last_data)
    future_predictions.append(future_pred[0])
    last_data = np.append(last_data[:, 1:], future_pred.reshape(1, 1), axis=1)

# Gelecek tahminlerini geri ölçeklendirelim
future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))

# Gelecek tahminlerini zaman serisi ile birleştirelim
future_dates = pd.date_range(start=data.index[-1] + pd.DateOffset(months=1), periods=50*12, freq='M')
future_spi = pd.DataFrame(data=future_predictions, index=future_dates, columns=['spi'])

# 2023 yılından itibaren sonuçları göstermek için yeni bir DataFrame oluşturun
start_date = '2023-12-01'
result_index = data.index.append(future_spi.index)
results = pd.DataFrame(index=result_index[result_index >= start_date], columns=['Gerçek Değerler', 'Eğitim Tahminleri', 'Test Tahminleri', 'Gelecek Tahminleri'])

# 2023'ten itibaren olan gerçek değerleri ekleyelim
results['Gerçek Değerler'] = data['spi'][data.index >= start_date]

# Eğitim ve test tahminlerini sadece 2023'ten itibaren ekleyelim
results['Eğitim Tahminleri'] = np.nan
results['Test Tahminleri'] = np.nan

train_predict_index = data.index[look_back:len(train_predict)+look_back]
test_predict_index = data.index[len(train_predict)+(look_back*2)+1:len(spi_values)-1]

results.loc[train_predict_index[train_predict_index >= start_date], 'Eğitim Tahminleri'] = train_predict.flatten()[train_predict_index >= start_date]
results.loc[test_predict_index[test_predict_index >= start_date], 'Test Tahminleri'] = test_predict.flatten()[test_predict_index >= start_date]

# Gelecek tahminlerini ekleyelim
results.loc[future_spi.index, 'Gelecek Tahminleri'] = future_predictions.flatten()

# Sonuçları bir Excel dosyasına yazdıralım
results.to_excel('spi_tahmin_sonuclari_1.xlsx')

# Sonuçları çizelim
plt.figure(figsize=(15, 6))
plt.plot(results.index, results['Gerçek Değerler'], label='Gerçek Değerler')
plt.plot(results.index, results['Eğitim Tahminleri'], label='Eğitim Tahminleri')
plt.plot(results.index, results['Test Tahminleri'], label='Test Tahminleri')
plt.plot(results.index, results['Gelecek Tahminleri'], label='Gelecek Tahminleri')
plt.legend()
plt.savefig('gelecek_tahminleri_spi.png')
plt.show()

# Performans ölçütlerini hesaplayalım
train_rmse = np.sqrt(mean_squared_error(y_train, train_predict))
train_mae = mean_absolute_error(y_train, train_predict)
train_r2 = r2_score(y_train, train_predict)

print(f"Training RMSE: {train_rmse}")
print(f"Training MAE: {train_mae}")
print(f"Training R2: {train_r2}")

# Grafikleri kaydedeceğimiz klasörü oluşturalım
os.makedirs('plots_spi', exist_ok=True)

# Grafikleri klasöre kaydedelim
plt.figure(figsize=(15, 6))
plt.plot(data.index, spi_values, label='Gerçek Değerler')
plt.plot(data.index, train_predict_plot, label='Eğitim Tahminleri')
plt.plot(data.index, test_predict_plot, label='Test Tahminleri')
plt.legend()
plt.savefig('plots_spi/tahmin_sonuclari_spi.png')
plt.show()

plt.figure(figsize=(15, 6))
plt.plot(results.index, results['Gerçek Değerler'], label='Gerçek Değerler')
plt.plot(results.index, results['Eğitim Tahminleri'], label='Eğitim Tahminleri')
plt.plot(results.index, results['Test Tahminleri'], label='Test Tahminleri')
plt.plot(results.index, results['Gelecek Tahminleri'], label='Gelecek Tahminleri')
plt.legend()
plt.savefig('plots_spi/gelecek_tahminleri_spi.png')
plt.show()
